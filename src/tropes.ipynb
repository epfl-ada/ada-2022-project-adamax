{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helpers\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import tropes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two datasets: one from TVTropes and the CMU one. Since the TVTropes dataset only has titles, we can only use the titles to merge with the CMU dataset.\n",
    "\n",
    "In both datasets, we drop all movies that have duplicated titles (after some preprocessing on the title text). This means that all occurrences of such movies are filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tvtropes = tropes.get_tvtropes_movies(\"../data/tvtropes_20200302.json\")\n",
    "df_cmu = helpers.get_movies()\n",
    "df_merged = tropes.merge_cmu_with_tvtropes(df_cmu, df_tvtropes)\n",
    "df_merged = tropes.add_bob_indicator(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tropes = [tr for tropes in df_merged.trope.values for tr in tropes if tr != \"boxofficebomb\"]\n",
    "all_tropes_bombs = [tr for tropes in df_merged.trope.values for tr in tropes if \"boxofficebomb\" in tropes and tr != \"boxofficebomb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(all_tropes)\n",
    "counts_bombs = Counter(all_tropes_bombs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_counts(counts, normalizing_const=None):\n",
    "    if normalizing_const is None:\n",
    "        normalizing_const = sum(counts.values(), 0.0)\n",
    "    for key in counts:\n",
    "        counts[key] /= normalizing_const\n",
    "        counts[key] *= 100\n",
    "        # counts[key] = np.round(counts[key], 3)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = normalize_counts(counts, df_merged.shape[0])\n",
    "counts_bombs = normalize_counts(counts_bombs, df_merged[\"is_bob\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = counts.most_common(100)\n",
    "res1 = {}\n",
    "for k, v in res_1:\n",
    "    res1[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = counts_bombs.most_common(100)\n",
    "res2 = {}\n",
    "for k, v in res_2:\n",
    "    res2[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropes_feat = list(res1.keys())\n",
    "trope_ind_mat = np.zeros((len(df_merged), len(tropes_feat)))\n",
    "\n",
    "for i, feat in enumerate(tropes_feat):\n",
    "    all_ind = []\n",
    "    for v in df_merged[\"trope\"].values:\n",
    "        all_ind.append(feat in v)\n",
    "    trope_ind_mat[:, i] = all_ind\n",
    "trope_ind_mat = pd.DataFrame(trope_ind_mat, columns=tropes_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.369822\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "model = sm.Logit(df_merged[\"is_bob\"].values, sm.add_constant(trope_ind_mat))\n",
    "res = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filmsof20102014             1.620407\n",
       "filmsof19951999             1.604104\n",
       "filmsof19901994             1.395992\n",
       "filmsof20002004             1.338109\n",
       "filmsof20052009             1.209386\n",
       "americanfilms               1.055539\n",
       "starderailingrole           1.038481\n",
       "filmsofthe1980s             0.983603\n",
       "creatorkiller               0.925786\n",
       "filmsdiscussedbymoviebob    0.766262\n",
       "troubledproduction          0.640401\n",
       "playingagainsttype          0.498583\n",
       "thedragon                   0.475164\n",
       "horrorfilms                -0.924672\n",
       "const                      -3.653670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.params[res.pvalues[res.pvalues < 0.05/100].index].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments = pd.read_csv(\"../data/MovieSummaries/plot_sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df_sentiments, df_merged, on=\"wiki_id\")\n",
    "# df2[\"label\"] = df2[\"label\"].replace({\"POSITIVE\": 1, \"NEGATIVE\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "NEGATIVE    4465\n",
       "POSITIVE    1646\n",
       "Name: wiki_id, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"label\")[\"wiki_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.1910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.826</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:26:48</td>     <th>  Log-Likelihood:    </th> <td> -3061.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6111</td>      <th>  AIC:               </th> <td>   6129.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6108</td>      <th>  BIC:               </th> <td>   6150.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.1749</td> <td>    0.043</td> <td>    4.077</td> <td> 0.000</td> <td>    0.091</td> <td>    0.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score</th> <td>    0.0256</td> <td>    0.046</td> <td>    0.554</td> <td> 0.580</td> <td>   -0.065</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>label</th> <td>   -0.0009</td> <td>    0.006</td> <td>   -0.156</td> <td> 0.876</td> <td>   -0.012</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1298.123</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2330.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.507</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.270</td>  <th>  Cond. No.          </th> <td>    18.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.1910\n",
       "Date:                Fri, 18 Nov 2022   Prob (F-statistic):              0.826\n",
       "Time:                        18:26:48   Log-Likelihood:                -3061.7\n",
       "No. Observations:                6111   AIC:                             6129.\n",
       "Df Residuals:                    6108   BIC:                             6150.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.1749      0.043      4.077      0.000       0.091       0.259\n",
       "score          0.0256      0.046      0.554      0.580      -0.065       0.116\n",
       "label         -0.0009      0.006     -0.156      0.876      -0.012       0.011\n",
       "==============================================================================\n",
       "Omnibus:                     1298.123   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2330.162\n",
       "Skew:                           1.507   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.270   Cond. No.                         18.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = sm.OLS(df2[\"is_bob\"].values, sm.add_constant(df2[[\"score\", \"label\"]]))\n",
    "res2 = model2.fit()\n",
    "res2.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42cbe137d1eb0b05077e25ded00aae12b48391c903ae2922613505c4ac843849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
